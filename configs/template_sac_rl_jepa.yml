threads: 2
processes: 1
seed: 1234
env:
  own_env: True
  env_fn: DiscreteGridWorld
  action_space_type: discreteNN
  state_space_type: discrete
  env_config:
    max_steps: 150
    max_step_length: 0.2
    num_actuators: 10
    num_bins: 40
    feature_dict:
      obstacles:
        - x: 0
          y: 15
          x2: 20
          y2: 16
        - x: 20
          y: 15
          x2: 21
          y2: 30
      goals:
        - coords:
            x: 5
            y: 25
            x2: 7
            y2: 27
          reward: 1
model:
  ac_fn: SACActorCriticEmbed
  config:
    hidden_sizes_actor: [64, 64]
    hidden_sizes_critic: [64, 64]
    std_dev_actor: 0.6
embed:
  # Choose one of the embedding modules in embedding_modules
  embed_module: SASEmbeddingModule
  continuous_learning: False
  load_emb_path: None
  learning_rate: 0.01
  train_iters: 1
  batch_size: 64
  # Embedding dimensionality for the state and action
  s_embed_dim: 8
  a_embed_dim: 2
  update_every_n_steps: 2000
  use_full_buffer: False
  train_on_n_samples: 500
  save_pretrain_embeddings: True
  # The embedding module can be pre-trained using the below config
  pre_train:
    is_on: True
    batch_size: 256
    train_iters: 10
    samples: 3_000
    freeze_first_layer: False
    fine_tune_iters: 50
training:
  num_epochs: 10
  steps_per_epoch: 500
  buffer_size: 1_000_000
  gamma: 0.9
  polyak: 0.999
  learning_rate_pi: 0.0003
  learning_rate_q: 0.0003
  update_iters: 50
  max_ep_len: 150
  save_freq: 100
  num_test_episodes: 2
  alpha: 0.1
  act_limit: 1.1
  random_exp_steps: 100
  batch_size: 512
  kl_lambda_pi: 1
  kl_lambda_phi: 1
  num_obs_samples: 5
  masking_percentage: 0.2
logger:
  log_every_n_epochs: 1
  output_dir: "experiments/sac_test"
